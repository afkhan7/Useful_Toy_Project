{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"detectron2_Faster_rcnns.ipynb","private_outputs":true,"provenance":[{"file_id":"1_4qbuaIgLkvKiS_jAAvcbLquxVlCLryV","timestamp":1655555769979}],"machine_shape":"hm","collapsed_sections":[],"authorship_tag":"ABX9TyOCevGR5jcyR3LnxRQYH1Ek"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#모델 추론 결과값 저장\n","\n"],"metadata":{"id":"zHagskUY2h6a"}},{"cell_type":"markdown","source":["### 목표 \n","- Detectron2 Faster RCNN 모델 3가지에 대해서 COCO Val2017 데이터를 이용하여 추론 결과 저장\n","- R101-DC5\n","- R101-FPN\n","- X101-FPN\n","\n"],"metadata":{"id":"EPUVEydgGPM2"}},{"cell_type":"markdown","source":["# 1. 데이터 준비\n"],"metadata":{"id":"l7Junyog2r08"}},{"cell_type":"markdown","source":["## 1) 자원 확인"],"metadata":{"id":"SStaSUPT3F0x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0xSTr2G2K3w"},"outputs":[],"source":["!nvidia-smi\n","!nproc"]},{"cell_type":"code","source":["%mkdir coco\n","%cd coco\n","%mkdir images\n","%cd images\n"],"metadata":{"id":"d8bWh_6m4Dza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget http://images.cocodataset.org/zips/val2017.zip"],"metadata":{"id":"FzEuZDut5KR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip val2017.zip\n","%rm val2017.zip\n","%cd ../"],"metadata":{"id":"GVCWjSgo4JlL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip"],"metadata":{"id":"TjePg3q65Poh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip annotations_trainval2017.zip\n","%rm annotations_trainval2017.zip"],"metadata":{"id":"gwspuxFP5gkD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pwd"],"metadata":{"id":"XyLSvYeR5jvs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_path = '/content/coco/images/val2017/'"],"metadata":{"id":"tzzoibY43g41"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3-1) 데이터셋 수량 확인"],"metadata":{"id":"lB6ozO783oi4"}},{"cell_type":"code","source":["from glob import glob\n","img_list = glob(dataset_path + '*.jpg')\n","print('coco val2017 data count (raw): ' + str(len(img_list)))"],"metadata":{"id":"M_clKP8X4wyO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3-2) 화면 출력을 통해 데이터 이미지의 정상 로드 확인 "],"metadata":{"id":"oQQ-4hqp36Og"}},{"cell_type":"code","source":["from IPython.display import Image, clear_output\n","Image(filename=img_list[3], width=300)"],"metadata":{"id":"489N45aIc68s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. 모델 추론\n","- Detectron2 및 필요한 패키지 설치    \n","reference : https://github.com/facebookresearch/detectron2"],"metadata":{"id":"w5llwo2E85r3"}},{"cell_type":"code","source":["!python -m pip install pyyaml==5.1\n","!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n","!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"],"metadata":{"id":"yEZBfVWr2zl-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- torch, detectron2 버전 체크"],"metadata":{"id":"lqvN9gq19VBe"}},{"cell_type":"code","source":["import torch, detectron2\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"],"metadata":{"id":"4mcRxqFf20tJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.data import DatasetMapper, build_detection_test_loader, build_detection_train_loader\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import os, json, cv2, random\n","import logging\n","import datetime\n","import time"],"metadata":{"id":"Kjuom7Dw25h8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1) detectron2 데이터셋"],"metadata":{"id":"vcci0I_Q9DYI"}},{"cell_type":"markdown","source":["### 1-1) detectron2 데이터셋 등록"],"metadata":{"id":"oTafWcSJ_rGX"}},{"cell_type":"code","source":["register_coco_instances(\"coco_2017\", {}, \"/content/coco/annotations/instances_val2017.json\", dataset_path)  "],"metadata":{"id":"e1Wl8jj_3GW6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1-2) 등록된 데이터셋 체크"],"metadata":{"id":"DPbAQPau9cMN"}},{"cell_type":"code","source":["dataset_dicts = DatasetCatalog.get(\"coco_2017\")\n","coco_2017_metadata = MetadataCatalog.get(\"coco_2017\")\n","\n","for d in random.sample(dataset_dicts, 3):\n","    print(d[\"file_name\"])\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=coco_2017_metadata, scale=0.5)\n","    out = visualizer.draw_dataset_dict(d)\n","    cv2_imshow(out.get_image()[:, :, ::-1])"],"metadata":{"id":"65-1nyZs__G6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2) 모델 세팅"],"metadata":{"id":"1EarlFFf-fVE"}},{"cell_type":"code","source":["cfg0 = get_cfg()\n","cfg0.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml\"))\n","cfg0.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml\")\n","cfg1 = get_cfg()\n","cfg1.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n","cfg1.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n","cfg2 = get_cfg()\n","cfg2.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n","cfg2.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n","predictor0 = DefaultPredictor(cfg0)\n","predictor1 = DefaultPredictor(cfg1)\n","predictor2 = DefaultPredictor(cfg2)"],"metadata":{"id":"wX-0PgOV__Jj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3) 추론 결과 시각화"],"metadata":{"id":"UOo6W6BB61TT"}},{"cell_type":"code","source":["test_metadata = MetadataCatalog.get(\"coco_2017\")\n","test_dataset_dicts = DatasetCatalog.get(\"coco_2017\")\n","for d in random.sample(test_dataset_dicts, 3):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor0(im)  \n","    v = Visualizer(im[:, :, ::-1], metadata=test_metadata, scale=0.4)\n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(out.get_image()[:, :, ::-1])"],"metadata":{"id":"LLf5KEnV0LHB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4) cocoEvaluator를 이용하여 AP, AR 값 평가 "],"metadata":{"id":"ll1akzqx66IH"}},{"cell_type":"code","source":["def cocoEval(predictor, cfg):\n","  evaluator = COCOEvaluator(\"coco_2017\", output_dir=cfg.OUTPUT_DIR)\n","  val_loader = build_detection_test_loader(cfg, \"coco_2017\")\n","  print(inference_on_dataset(predictor.model, val_loader, evaluator))"],"metadata":{"id":"jctyqg2rF3No"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cocoEval(predictor0, cfg0)"],"metadata":{"id":"tDN2HRgYj2Ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cocoEval(predictor1, cfg1)"],"metadata":{"id":"EvttbTFgjzv4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cocoEval(predictor2, cfg2)"],"metadata":{"id":"JeFCHZ3pKjKM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5) 추론 결과 저장"],"metadata":{"id":"0VXoaxdySY9A"}},{"cell_type":"markdown","source":["PredictionString: 결과물 리스트. 각 Bounding box 당 label, score, x1, y1, x2, y2 (ex. \"62 0.99 597.3 518.4 954.3 1021.3\")    \n","file_name: 이미지 파일 이름. (ex. 000000000139.jpg)    \n","width: 이미지 너비. (ex. 640)    \n","height: 이미지 높이. (ex. 426)    \n","image_id: dataset에 등록된 id. (ex. 139)    "],"metadata":{"id":"WQzyaLRNVlkw"}},{"cell_type":"code","source":["import csv\n","from tqdm import tqdm\n","\n","# 추론 결과물을 위에서 정의한 형식으로 csv 파일 생성\n","def to_csvfile(predictor, dataset_dicts, file_path ='/content/results.csv'):\n","  file_name = file_path.split('/')[-1]\n","  dir_path = file_path[:len(file_path) - len(file_name)]\n","  if not os.path.exists(dir_path): \n","    file_path = '/content/' + file_name\n","\n","  with open(file_path, 'w') as submission_csv:\n","    csv_writer = csv.DictWriter(submission_csv, fieldnames=['PredictionString', 'file_name', 'width', 'height','image_id'])\n","    csv_writer.writeheader()\n","\n","    for d in tqdm(dataset_dicts):\n","      image_path = d[\"file_name\"]\n","      im = cv2.imread(image_path)\n","      outputs = predictor(im)\n","      PredictionString = ''\n","      classes = outputs[\"instances\"].to(\"cpu\").pred_classes.numpy()\n","      bboxes = outputs[\"instances\"].to(\"cpu\").pred_boxes.tensor.numpy()\n","      scores = outputs[\"instances\"].to(\"cpu\").scores.numpy()\n","      for c_idx in range(len(classes)):\n","        PredictionString += f'{classes[c_idx]} {scores[c_idx]} {bboxes[c_idx][0]} {bboxes[c_idx][1]} {bboxes[c_idx][2]} {bboxes[c_idx][3]} '\n","      csv_writer.writerow({'PredictionString': PredictionString, 'file_name': image_path.split('/')[-1], 'width': d[\"width\"],'height': d[\"height\"],'image_id': d[\"image_id\"]})"],"metadata":{"id":"4U_q-uXNxTQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["to_csvfile(predictor0, test_dataset_dicts, '/content/results0.csv')"],"metadata":{"id":"NliEC5isTifS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["to_csvfile(predictor1, test_dataset_dicts, '/content/results1.csv')"],"metadata":{"id":"CPthzSRDVLxd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["to_csvfile(predictor2, test_dataset_dicts, '/content/results2.csv')"],"metadata":{"id":"MjYHYpdYVL70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install ensemble-boxes"],"metadata":{"id":"gA_RLikeYSdu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, json, time\n","import pandas as pd\n","import numpy as np\n","from ensemble_boxes import *\n","from tqdm import tqdm\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","\n","id_matching = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32,\n","               33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n","               60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]"],"metadata":{"id":"8HWMVp7LX0QW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_csv(path):\n","    if os.path.isfile(path):  # path 파일이 있다면\n","        with open(path, 'r', encoding='UTF-8') as csvf:\n","            data = pd.read_csv(csvf)\n","        return data\n","    else:\n","        print('path is wrong')"],"metadata":{"id":"M6LcwyFmYj8_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_format_step2(labels_list, scores_list, boxes_list, data, index, h, w):\n","    pstring = data['PredictionString'][index]\n","    if type(pstring) is float and np.isnan(pstring):  # 해당 이미지에 대한 결과가 없다면 리턴\n","        return\n","\n","    n_pstring = np.array(pstring.split(' '))\n","    n_pstring = np.delete(n_pstring, len(n_pstring) - 1)\n","\n","    for idx in range(len(n_pstring) // 6):\n","        idx6 = idx * 6\n","        label = float(id_matching[int(n_pstring[idx6])])\n","        score = float(n_pstring[idx6 + 1])\n","        x1 = float(n_pstring[idx6 + 2]) / w\n","        y1 = float(n_pstring[idx6 + 3]) / h\n","        x2 = float(n_pstring[idx6 + 4]) / w\n","        y2 = float(n_pstring[idx6 + 5]) / h\n","\n","        labels_list.append(label)\n","        scores_list.append(score)\n","        boxes_list.append([x1, y1, x2, y2])"],"metadata":{"id":"lzU-DjWYYmtt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_format_step1(labels_lists, scores_lists, boxes_lists, weights, data, row_idx, model_idx, h, w, weights_size):\n","    labels_list = []\n","    scores_list = []\n","    boxes_list = []\n","    convert_format_step2(labels_list, scores_list, boxes_list, data, row_idx, h, w)\n","    if len(labels_list) != 0:\n","        weights.append(weights_size[model_idx])\n","        labels_lists.append(labels_list)\n","        scores_lists.append(scores_list)\n","        boxes_lists.append(boxes_list)\n"],"metadata":{"id":"wkLbILEJYpXf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def do_ensemble(save_path, datas, weights_size):\n","    with open(save_path, 'wt', encoding='UTF-8') as coco:\n","        ann = []\n","        start0 = time.time()\n","        for row_idx in tqdm(range(len(datas[0]))):\n","            image_id = datas[0]['image_id'][row_idx]\n","            w = datas[0]['width'][row_idx]\n","            h = datas[0]['height'][row_idx]\n","\n","            labels_lists = []\n","            scores_lists = []\n","            boxes_lists = []\n","            weights = []\n","\n","            for model_idx in range(len(datas)):\n","                convert_format_step1(labels_lists, scores_lists, boxes_lists, weights, datas[model_idx], row_idx,\n","                                     model_idx, h, w, weights_size)\n","\n","            if len(labels_lists) == 0:\n","                continue\n","            else:\n","                # boxes, scores, labels = nms(boxes_lists, scores_lists, labels_lists, weights=weights, iou_thr=0.5) # 0.439\n","                # boxes, scores, labels = soft_nms(boxes_lists, scores_lists, labels_lists, weights=weights, iou_thr=0.5, sigma=0.1, thresh=0.0001) # 0.440\n","                # boxes, scores, labels = non_maximum_weighted(boxes_lists, scores_lists, labels_lists, weights=weights, iou_thr=0.5, skip_box_thr=0.0001) # 0.447\n","                # boxes, scores, labels = weighted_boxes_fusion(boxes_lists, scores_lists, labels_lists, weights=weights, iou_thr=0.5, skip_box_thr=0.0001) # 0.454\n","                # boxes, scores, labels = weighted_boxes_fusion(boxes_lists, scores_lists, labels_lists, weights=weights, iou_thr=0.6, skip_box_thr=0.001) # 0.459\n","                boxes, scores, labels = weighted_boxes_fusion(boxes_lists, scores_lists, labels_lists, weights=weights, iou_thr=0.7, skip_box_thr=0.001)  # 0.460\n","                # boxes, scores, labels = weighted_boxes_fusion(boxes_lists, scores_lists, labels_lists, weights=weights, iou_thr=0.8, skip_box_thr=0.001) # 0.459\n","\n","                for c_idx in range(len(labels)):\n","                    ann += [{'image_id': int(image_id),\n","                             'category_id': int(labels[c_idx]),\n","                             'bbox': [boxes[c_idx][0] * w,\n","                                      boxes[c_idx][1] * h,\n","                                      (boxes[c_idx][2] - boxes[c_idx][0]) * w,\n","                                      (boxes[c_idx][3] - boxes[c_idx][1]) * h],\n","                             'score': float(scores[c_idx]), }]\n","\n","        json.dump(ann, coco)\n","    print('{} images, duration time : {} [sec]'.format(len(datas[0]), time.time() - start0))\n"],"metadata":{"id":"EDtnZkswYrQh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. file load\n","path0 = '/content/results0.csv'  # 40.631\n","path1 = '/content/results1.csv'  # 42.036\n","path2 = '/content/results2.csv'  # 43.047\n","data0 = load_csv(path0)\n","data1 = load_csv(path1)\n","data2 = load_csv(path2)\n","datas = []\n","datas.append(data0)\n","datas.append(data1)\n","datas.append(data2)"],"metadata":{"id":"bhR43K85a1TF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. format convert & ensemble\n","weights_size = [1, 2, 3]\n","save_path = '/content/ensemble.json'\n","do_ensemble(save_path, datas, weights_size)"],"metadata":{"id":"5HcxCuEFZABw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. evaluate COCO AP\n","coco_gt = COCO('/content/coco/annotations/instances_val2017.json')\n","image_ids = sorted(coco_gt.getImgIds())\n","coco_dt = coco_gt.loadRes(save_path)\n","coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n","coco_eval.params.imgIds = image_ids\n","coco_eval.evaluate()\n","coco_eval.accumulate()\n","coco_eval.summarize()"],"metadata":{"id":"-XzFl2J7ZCdJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import os\n","#os._exit(00)"],"metadata":{"id":"-ZqXVNz4DJqH"},"execution_count":null,"outputs":[]}]}